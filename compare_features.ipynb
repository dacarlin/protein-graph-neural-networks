{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "import torch \n",
    "import numpy as np \n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.transforms import PointPairFeatures, KNNGraph\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from ingraham.struct2seq.protein_features import ProteinFeatures\n",
    "from ingraham.struct2seq.data import StructureDataset, StructureLoader\n",
    "from ingraham.experiments.utils import featurize\n",
    "from ingraham.struct2seq.struct2seq import Struct2Seq\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = StructureDataset(\"data/cath/chain_set.jsonl\", truncate=3, verbose=True, max_length=512)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12as.A', '132l.A', '153l.A']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d[\"name\"] for d in dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330, 129, 185]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = StructureLoader(dataset, batch_size=10_000, shuffle=False)\n",
    "\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['seq', 'coords', 'num_chains', 'name', 'CATH'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    break\n",
    "\n",
    "batch[0].keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 330, 4, 3]), torch.Size([3, 330]), torch.Size([3, 330]), (3,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# featurize with ingrham \n",
    "\n",
    "result = featurize(batch, device)\n",
    "\n",
    "X, S, mask, lengths = result \n",
    "\n",
    "X.shape, S.shape, mask.shape, lengths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.0160, 17.0520, 68.6860])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, 50, 0]  # coords of the N atom, residue 50, first structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Documents/inverse-folding-unrolled/ingraham/struct2seq/protein_features.py:231: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Cross.cpp:66.)\n",
      "  n_2 = F.normalize(torch.cross(u_2, u_1), dim=-1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 330, 20])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we then pass this to the model \n",
    "\n",
    "hidden = 128 \n",
    "neighbors = 16 \n",
    "\n",
    "model = Struct2Seq(num_letters=20, node_features=hidden, edge_features=hidden, hidden_dim=hidden, k_neighbors=neighbors, \n",
    "            protein_features=\"full\")\n",
    "\n",
    "logits = model(X, S, lengths, mask)\n",
    "\n",
    "logits.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the model as implemented here outputs the logits for each of the residues in each sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 330, 128]),\n",
       " torch.Size([3, 330, 16, 128]),\n",
       " torch.Size([3, 330, 16]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but inside the model, there are two steps, first the `ProteinFeatures` then the transformer \n",
    "\n",
    "features = ProteinFeatures(hidden, hidden, num_positional_embeddings=16, num_rbf=16, top_k=neighbors, features_type=\"full\")\n",
    "\n",
    "result = features.forward(X, lengths, mask)\n",
    "\n",
    "V, E, E_idx = result \n",
    "\n",
    "V.shape, E.shape, E_idx.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 330, 4, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same deal for ProteinMPNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProteinMPNN.training.model_utils import featurize as justas_featurize\n",
    "from ProteinMPNN.training.model_utils import ProteinMPNN\n",
    "from ProteinMPNN.training.model_utils import ProteinFeatures as JustasProteinFeatures \n",
    "from ProteinMPNN.training.utils import StructureDataset as JustasStructureDataset\n",
    "from ProteinMPNN.training.utils import StructureLoader as JustasStructureLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justas_raw_data = []\n",
    "max_samples = 3 \n",
    "\n",
    "def transform_for_justas(pkg):\n",
    "    pkg[\"masked_list\"] = []\n",
    "    pkg[\"visible_list\"] = [pkg[\"name\"][5]]\n",
    "    pkg[f\"seq_chain_{pkg['name'][5]}\"] = pkg[\"seq\"]\n",
    "    pkg[\"num_of_chains\"] = 1\n",
    "    for backbone_atom in [\"N\", \"CA\", \"C\", \"O\"]:\n",
    "        pkg[\"coords\"][f\"{backbone_atom}_chain_{pkg['name'][5]}\"] = pkg[\"coords\"][backbone_atom]\n",
    "    pkg[f\"coords_chain_{pkg['name'][5]}\"] = pkg[\"coords\"]\n",
    "    \n",
    "    return pkg \n",
    "\n",
    "with open(\"data/cath/chain_set.jsonl\") as fn:\n",
    "    count = 0 \n",
    "    for line in fn.readlines():\n",
    "        pkg = json.loads(line)\n",
    "        pkg = transform_for_justas(pkg)\n",
    "        justas_raw_data.append(pkg)\n",
    "        count +=1 \n",
    "        if count >= max_samples:\n",
    "            break \n",
    "\n",
    "len(justas_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justas_dataset = JustasStructureDataset(justas_raw_data, max_length=512)\n",
    "\n",
    "len(justas_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ProteinMPNN.training.utils.StructureLoader at 0x30f058a50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justas_loader = JustasStructureLoader(justas_dataset, batch_size=10_000, shuffle=False)\n",
    "\n",
    "justas_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for justas_batch in justas_loader:\n",
    "    X, S, mask, lengths, chain_M, residue_idx, mask_self, chain_encoding_all = justas_featurize(justas_batch, device)\n",
    "\n",
    "len(justas_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Documents/inverse-folding-unrolled/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "justas_model = ProteinMPNN(k_neighbors=neighbors)\n",
    "\n",
    "logits = justas_model.forward(X, S, mask, chain_M, residue_idx, chain_encoding_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 330, 21])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing here, the model takes the XYZ directly and then, internally, does ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 330, 16, 128]), torch.Size([3, 330, 16]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justas_features = JustasProteinFeatures(hidden, hidden, num_positional_embeddings=16, num_rbf=16, top_k=neighbors, num_chain_embeddings=16)\n",
    "\n",
    "E, E_idx = justas_features.forward(X, mask, residue_idx, chain_encoding_all)\n",
    "\n",
    "E.shape, E_idx.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so internally, the model takes our XYZ features and then outputs edge features `E` as well as a matrix `E_idx` which provides a list of the neightbors for each of 330 residues in the 3 proteins in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now now all we need really is a new network \n",
    "\n",
    "# that accepts the XYZ and outputs the logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but first let's load this into PyG data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[330, 128], edge_index=[2, 5280], edge_attr=[5280, 128], y=[330]), 128)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "itos = {i: letter for i, letter in enumerate(alphabet)}\n",
    "stoi = {v: k for k, v in itos.items()}    \n",
    "vocab_size = len(set(alphabet))\n",
    "\n",
    "features = ProteinFeatures(hidden, hidden, num_positional_embeddings=16, num_rbf=16, top_k=neighbors, features_type=\"full\")\n",
    "\n",
    "def transform_for_pyg(pkg):\n",
    "    X, S, mask, lengths = featurize([pkg], device)\n",
    "    # print(lengths)\n",
    "    V, E, E_idx = features.forward(X, lengths, mask)\n",
    "    tokens = torch.tensor(list(stoi[s] for s in pkg[\"seq\"])).detach() \n",
    "    edges_1 = []\n",
    "    edges_2 = [] \n",
    "    edge_index = 0 \n",
    "    edge_attr = []\n",
    "    for seq_pos in range(S.shape[1]):\n",
    "        neighbors = E_idx[0, seq_pos]\n",
    "        for nbr_idx, neighbor in enumerate(neighbors):\n",
    "            # the edge is between seq_pos, and neighbor \n",
    "            edges_1.append(seq_pos)\n",
    "            edges_2.append(neighbor)\n",
    "\n",
    "            # get the data from `E`, recall E is [batch, seq, k, features] and you just want [features] for a particular one \n",
    "            # this one, in fact \n",
    "            my_edge_features = E[0, seq_pos, nbr_idx]\n",
    "            edge_attr.append(my_edge_features)\n",
    "            edge_index += 1\n",
    "\n",
    "    edge_attr = torch.tensor(np.stack(edge_attr), dtype=torch.long)\n",
    "    edges = torch.tensor((edges_1, edges_2)).detach()\n",
    "    data = Data(x=V[0].detach(), edge_attr=edge_attr, edge_index=edges, y=tokens)\n",
    "    return data \n",
    "\n",
    "\n",
    "max_samples = 128 \n",
    "pyg_data = [] \n",
    "names = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    with open(\"data/cath/chain_set.jsonl\") as fn:\n",
    "        count = 0 \n",
    "        for line in fn.readlines():\n",
    "            try:\n",
    "                pkg = json.loads(line)\n",
    "                pkg = transform_for_pyg(pkg)\n",
    "                pyg_data.append(pkg)\n",
    "                #names.append(pkg[\"name\"])\n",
    "                count +=1 \n",
    "            except:\n",
    "                pass\n",
    "            if count >= max_samples:\n",
    "                break \n",
    "\n",
    "pyg_data[0], len(pyg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5280, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(pyg_data, batch_size=1)\n",
    "\n",
    "for batch in loader:\n",
    "    break \n",
    "\n",
    "batch.edge_attr.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
